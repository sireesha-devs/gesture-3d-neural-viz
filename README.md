

# Gesture-Controlled Neural Network Visualization Platform ğŸ–ï¸ğŸ§ 

An interactive web-based application that allows users to explore neural network concepts using **real-time hand gesture control**. This platform combines **computer vision**, **modern web technologies**, and **3D-style visual interaction** to make learning neural networks more intuitive and engaging.

The project focuses on **visualization and educational interaction** rather than training actual neural network models.

---

## ğŸš€ Key Features

- âœ‹ **Real-time Hand Gesture Detection** using MediaPipe  
- ğŸ“· **Live Webcam Integration**  
- ğŸ§  **Interactive Neural Network Visualization**  
- ğŸ® **Gesture-Based Interaction** (Rotate / Zoom / Navigate)  
- âš¡ **Fast Performance** with Vite + React  
- ğŸ¨ **Modern UI Design** using Tailwind CSS and shadcn/ui  
- ğŸ“± **Responsive Layout**  
- ğŸ”” **UI Feedback and Notifications**  

---

## ğŸ›  Tech Stack

### Frontend

- React (TypeScript)  
- Vite  
- Tailwind CSS  
- shadcn/ui  
- React Router  
- React Query  

### Computer Vision

- MediaPipe Hands  
- Web Camera API  

### Development Tools

- ESLint  
- PostCSS  
- Vitest  

---

## ğŸ“ Project Structure

project-root/
â”‚
â”œâ”€â”€ public/ # Static assets
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ components/ # Reusable UI components
â”‚ â”œâ”€â”€ pages/ # Application pages
â”‚ â”œâ”€â”€ hooks/ # Custom React hooks
â”‚ â”œâ”€â”€ lib/ # Utility functions
â”‚ â”œâ”€â”€ types/ # TypeScript type definitions
â”‚ â”œâ”€â”€ App.tsx
â”‚ â””â”€â”€ main.tsx
â”‚
â”œâ”€â”€ index.html
â”œâ”€â”€ package.json
â”œâ”€â”€ vite.config.ts
â””â”€â”€ tailwind.config.ts


---

## âš™ï¸ Installation and Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <your-github-repo-url>
cd project-folder-name
2ï¸âƒ£ Install Dependencies
npm install
3ï¸âƒ£ Start Development Server
npm run dev
4ï¸âƒ£ Open in Browser
Open the application in your browser:

http://localhost:5173
Port number may change depending on availability.

ğŸ“· Camera Permission (Important)
This project requires webcam access for gesture recognition.

When prompted by your browser:

Allow this site to use your camera?
Click Allow.

âœ‹ How Gesture Detection Works
Uses MediaPipe Hands for real-time hand landmark detection

Tracks 21 hand keypoints per frame

Processes continuous gesture movement

Maps gestures to UI interaction events

Enables intuitive neural network visualization control

ğŸ“¦ Production Build
To create an optimized production build:

npm run build
Build files will be generated inside:

dist/
ğŸ§ª Run Tests (Optional)
npm run test
â— Common Issues and Solutions
Webcam Not Working
Check browser camera permissions

Use Google Chrome or Microsoft Edge

Close other applications using the webcam

Refresh the page

Hand Gesture Not Detected
Ensure proper lighting

Keep hand inside camera frame

Avoid cluttered background

Keep palm facing the camera

Application Not Loading
Run npm install again

Delete node_modules and reinstall dependencies

Restart development server

ğŸ¯ Project Objective
The main objective of this project is to create an interactive learning platform that helps users visually understand neural network structures using natural hand gestures, improving engagement and conceptual clarity.

ğŸš€ Future Enhancements
Multi-hand gesture support

Custom gesture mapping

Animated neural network layers

Model training visualization

VR / AR integration

ğŸ‘¨â€ğŸ’» Author
Sireesha Dwarapu
3rd Year Computer Science Engineering Student
AI / ML and Computer Vision Enthusiast

â­ Support and Contribution
If you find this project useful:

â­ Star the repository

ğŸ´ Fork the project

ğŸ Report issues

ğŸš€ Suggest improvements



