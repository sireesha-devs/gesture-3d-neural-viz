Gesture-Controlled Neural Network Visualization Platform ğŸ–ï¸ğŸ§ 

An interactive web-based application that allows users to explore neural network concepts using real-time hand gesture control. This platform combines computer vision, web technologies, and 3D-style visual interaction to make learning neural networks more intuitive and engaging.

The project focuses on visualization and educational interaction rather than training actual neural network models.

ğŸš€ Key Features

âœ‹ Real-time Hand Gesture Detection using MediaPipe

ğŸ“· Live Webcam Integration

ğŸ§  Interactive Neural Network Visualization

ğŸ® Gesture-Based Interaction (Rotate / Zoom / Navigate)

âš¡ Fast Performance with Vite + React

ğŸ¨ Modern UI with Tailwind CSS & shadcn/ui

ğŸ“± Responsive Design

ğŸ”” Toast Notifications and UI Feedback

ğŸ›  Tech Stack
Frontend

React (TypeScript)

Vite

Tailwind CSS

shadcn/ui

React Router

React Query

Computer Vision

MediaPipe Hands

Web Camera API

Tooling

ESLint

PostCSS

Vitest

ğŸ“ Project Structure
project-root/
â”‚
â”œâ”€â”€ public/               # Static assets
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/       # Reusable UI components
â”‚   â”œâ”€â”€ pages/            # Application pages
â”‚   â”œâ”€â”€ hooks/            # Custom React hooks
â”‚   â”œâ”€â”€ lib/              # Utility functions
â”‚   â”œâ”€â”€ types/            # TypeScript type definitions
â”‚   â”œâ”€â”€ App.tsx
â”‚   â””â”€â”€ main.tsx
â”‚
â”œâ”€â”€ index.html
â”œâ”€â”€ package.json
â”œâ”€â”€ vite.config.ts
â””â”€â”€ tailwind.config.ts

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone <your-github-repo-link>
cd project-folder-name

2ï¸âƒ£ Install Dependencies
npm install

3ï¸âƒ£ Run Development Server
npm run dev

4ï¸âƒ£ Open in Browser

After successful build, open:

http://localhost:5173


(Port may vary depending on availability)

ğŸ“· Camera Permission (Important)

This project requires webcam access for gesture detection.

âœ… Allow Camera Access

When prompted by browser:

Allow this site to use your camera?


Click Allow

âœ‹ How Gesture Detection Works

Uses MediaPipe Hands for real-time hand landmark detection

Tracks 21 hand keypoints

Processes gesture movement frames

Maps gestures to UI interaction events

Enables intuitive visualization control

ğŸ“¦ Production Build

To generate optimized production build:

npm run build


Output will be generated inside:

dist/

ğŸ§ª Run Tests (Optional)
npm run test

â— Common Issues & Solutions
âŒ Webcam Not Working

âœ” Check browser camera permission
âœ” Use Chrome or Edge
âœ” Close other apps using camera
âœ” Refresh the page

âŒ Hand Not Detected

âœ” Ensure proper lighting
âœ” Keep hand inside camera frame
âœ” Avoid cluttered background
âœ” Keep palm facing camera

âŒ App Not Loading

âœ” Run npm install again
âœ” Delete node_modules and reinstall
âœ” Restart dev server

ğŸ¯ Project Objective

The goal of this project is to create an interactive learning environment where users can visually understand neural network structures using natural hand gestures, improving engagement and conceptual clarity.

ğŸš€ Future Enhancements

Multi-hand gesture support

Gesture customization

Animated neural network layers

VR/AR visualization integration

Model training visualization

ğŸ‘¨â€ğŸ’» Author

Sireesha Dwarapu
3rd Year CSE Student
AI / ML & Computer Vision Enthusiast

â­ Support

If you like this project:

â­ Star the repository

ğŸ´ Fork it

ğŸ Report issues

ğŸš€ Suggest improvements
